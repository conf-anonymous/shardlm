Benchmark: V3-OT Secure Inference
Endpoint: v3-ot
Runs: 5
Max Tokens: 50
Timestamp: Wed Jan 14 22:34:58 UTC 2026

Results:
--------
ShardLM V2 Benchmark
========================================

Starting benchmark...
  Server:  http://localhost:9090
  Model:   Qwen2_5_1_5B
  GPU:     Unknown GPU
  Prompt:  19 tokens
  Runs:    5 (+ 3 warmup)

Running 3 warmup iterations...
  Warmup 1/3  Warmup 2/3  Warmup 3/3  Warmup complete.        
Running 5 benchmark iterations...

========================================
Benchmark Results
========================================
Model:     Qwen2_5_1_5B
GPU:       Unknown GPU
Version:   v3-ot
Endpoint:  /v3/ot/prefill
Timestamp: 2026-01-14 22:35:03 UTC

Configuration:
  Prompt tokens:   19
  Max new tokens:  50
  Temperature:     0.70
  Runs:            5
  Warmup:          3

Prefill (prompt processing):
  Mean:      483.4 ms
  Std:        37.5 ms
  Min:       419.1 ms
  Max:       524.6 ms
  P50:       484.4 ms
  P95:       524.6 ms
  P99:       524.6 ms

Total (end-to-end):
  Mean:      493.2 ms
  Std:        37.4 ms
  P95:       534.3 ms
  Tokens/sec: 39.3
========================================

Results saved to: /workspace/shardlm/benchmarks_results/20260114_223241/v3-ot_benchmark.json
